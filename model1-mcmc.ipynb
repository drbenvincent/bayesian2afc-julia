{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - MCMC with Turing.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Turing.jl (only need to do this once)\n",
    "See the Turing instructions on their [wiki](https://github.com/yebai/Turing.jl/wiki/Get-started#install-turingjl) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"Turing\")\n",
    "#Pkg.update()\n",
    "#Pkg.checkout(\"Turing\", \"master\") \n",
    "#Pkg.build(\"Turing\")\n",
    "#Pkg.test(\"Turing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mEnvironment variable CMDSTAN_HOME not found. Use set_cmdstan_home!.\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Turing]: AD chunk size is set as 40\n"
     ]
    }
   ],
   "source": [
    "using Turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Distributions, StatsFuns\n",
    "using Mamba: describe, plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: define data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Dict()\n",
    "data[\"T\"] = 100\n",
    "data[\"k\"] = [50, 51, 57, 55, 63, 62, 82, 94, 99, 100]\n",
    "data[\"Δμ\"] = [0.0100, 0.0215, 0.0464, 0.1000, 0.2154, 0.4642, 1.0000, 2.1544, 4.6416, 10.0000];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: conduct inference\n",
    "First we are going to define a model. This is the way of doing it for the Turing package. I managed to convert this over from the JAGS specification (see the original Matlab repo) with not so much trouble. It's pretty nice in fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model1 (generic function with 4 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model model1(k, Δμ, T) = begin\n",
    "    Φ(x) = normcdf(0, 1, x)\n",
    "    PC(Δμ, σ²) = Φ(Δμ/sqrt(2σ²))\n",
    "    σ² ~ Uniform(0,100)\n",
    "    for c ∈ 1:length(k)\n",
    "        k[c] ~ Binomial(T, PC(Δμ[c],σ²))\n",
    "    end\n",
    "    return σ²\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do sampling. Note that there are a variety of sampling algorithms we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Turing]:  Assume - `σ²` is a parameter\n",
      " @~(::ANY, ::ANY) at compiler.jl:76\n",
      "\r",
      "[Turing]:  Observe - `k` is an observation\n",
      " @~(::ANY, ::ANY) at compiler.jl:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[PG] Sampling... 79%  ETA: 0:00:01\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PG] Finished with\n",
      "  Running time    = 2.599131478000002;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[32m[PG] Sampling...100% Time: 0:00:03\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300-element Array{Float64,1}:\n",
       " 2.80942\n",
       " 1.09958\n",
       " 1.09958\n",
       " 1.09958\n",
       " 1.09958\n",
       " 1.09958\n",
       " 1.09958\n",
       " 1.09958\n",
       " 1.09958\n",
       " 1.09958\n",
       " 1.09958\n",
       " 1.09958\n",
       " 1.09958\n",
       " ⋮      \n",
       " 1.06908\n",
       " 1.06908\n",
       " 1.06908\n",
       " 1.06908\n",
       " 1.06908\n",
       " 1.06908\n",
       " 1.06908\n",
       " 1.06908\n",
       " 1.06908\n",
       " 1.06908\n",
       " 1.06908\n",
       " 1.06908"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 300\n",
    "samples = sample( model1(data[\"k\"], data[\"Δμ\"], data[\"T\"]), PG(50,n_samples))\n",
    "σ²posterior = samples[:σ²]\n",
    "\n",
    "# TODO: plot histogram of σ²posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: posterior prediction\n",
    "We'll now write our own function to do posterior prediction given the posterior samples of `σ²`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×300 Array{Int64,2}:\n",
       "  51   51   56   52   50   38   51   54  …   54   50   45   45   56   47   51\n",
       "  48   53   50   52   55   54   54   57      51   41   59   49   49   49   44\n",
       "  53   47   46   50   54   56   54   52      56   51   43   55   47   56   47\n",
       "  55   55   57   55   55   55   61   56      54   66   54   49   52   58   53\n",
       "  58   56   55   60   54   52   60   47      63   60   55   63   61   59   49\n",
       "  69   53   68   65   69   68   58   62  …   61   56   63   64   68   62   62\n",
       "  60   70   71   69   71   75   75   75      71   79   71   86   76   79   70\n",
       "  84   96   93   97   90   96   90   92      93   94   96   90   95   93   93\n",
       "  93  100  100  100  100  100  100  100     100  100   99  100  100  100  100\n",
       " 100  100  100  100  100  100  100  100     100  100  100  100  100  100  100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function posterior_prediction(T::Int64, Δμ_list, σ²samples)\n",
    "    Φ(x) = normcdf(0, 1, x)\n",
    "    PC(Δμ, σ²) = Φ(Δμ/sqrt(2σ²))\n",
    "    k_pred = zeros(n_samples, length(data[\"Δμ\"]))\n",
    "    k_pred = [rand(Binomial(T, PC(Δμ,σ²))) for Δμ ∈ Δμ_list, σ² ∈ σ²samples]\n",
    "end\n",
    "\n",
    "k_pred = posterior_prediction(data[\"T\"], data[\"Δμ\"], σ²posterior)\n",
    "# so now we have posterior predictive samples in k_pred.\n",
    "# Each row corresponds to an mcmc sample, each column corresponds to a value of Δμ\n",
    "\n",
    "\n",
    "# TODO: do summary stats or plotting of posterior predictions, and plot the actual data so we\n",
    "# can do model critique visually\n",
    "\n",
    "# TODO: can also do out of sample prediction simply by providing more values for Δμ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Vincent, B. T. (2015). A tutorial on Bayesian models of perception. Journal of Mathematical Psychology, 66, 103–114. http://doi.org/10.1016/j.jmp.2015.02.001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
